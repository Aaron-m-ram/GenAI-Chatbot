{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "hRW6IKqoXOFD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzMI0PfZNY_E",
        "outputId": "e13b8572-e3a4-438b-d69f-e8335abef85c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SDvSdi1IVk5M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Set Pandas options to display the full output\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "pd.set_option('display.max_rows', None)     # Show all rows\n",
        "pd.set_option('display.max_colwidth', None) # Display full content of each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jBPWmtZGVnoE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "749cf5d4-cd3f-4a92-ee70-dd1dfb9b7361"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                          conversation_history  \\\n",
              "0                                                                                                                                       Can we make this quick? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break up on the quad. Again. SEP   \n",
              "1                                                             Can we make this quick? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break up on the quad. Again. SEP Well I thought we'd start with pronunciation if that's okay with you. SEP   \n",
              "2  Can we make this quick? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break up on the quad. Again. SEP Well I thought we'd start with pronunciation if that's okay with you. SEP Not the hacking and gagging and spitting part. Please. SEP   \n",
              "3                                                                                                                                                                                                            You're asking me out. That's so cute. What's your name again? SEP   \n",
              "4                                                                                                                                                                                                                 No no it's my fault we didn't have a proper introduction SEP   \n",
              "\n",
              "                                                                  response  \n",
              "0    Well I thought we'd start with pronunciation if that's okay with you.  \n",
              "1                   Not the hacking and gagging and spitting part. Please.  \n",
              "2  Okay... then how 'bout we try out some French cuisine. Saturday? Night?  \n",
              "3                                                               Forget it.  \n",
              "4                                                                 Cameron.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1aec8e8-4fa8-441b-a6be-a1e4258b9ead\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_history</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Can we make this quick? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break up on the quad. Again. SEP</td>\n",
              "      <td>Well I thought we'd start with pronunciation if that's okay with you.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Can we make this quick? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break up on the quad. Again. SEP Well I thought we'd start with pronunciation if that's okay with you. SEP</td>\n",
              "      <td>Not the hacking and gagging and spitting part. Please.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Can we make this quick? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break up on the quad. Again. SEP Well I thought we'd start with pronunciation if that's okay with you. SEP Not the hacking and gagging and spitting part. Please. SEP</td>\n",
              "      <td>Okay... then how 'bout we try out some French cuisine. Saturday? Night?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You're asking me out. That's so cute. What's your name again? SEP</td>\n",
              "      <td>Forget it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No no it's my fault we didn't have a proper introduction SEP</td>\n",
              "      <td>Cameron.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1aec8e8-4fa8-441b-a6be-a1e4258b9ead')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1aec8e8-4fa8-441b-a6be-a1e4258b9ead button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1aec8e8-4fa8-441b-a6be-a1e4258b9ead');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c12dae6b-b90c-4d5a-a9b8-5cf632e30793\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c12dae6b-b90c-4d5a-a9b8-5cf632e30793')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c12dae6b-b90c-4d5a-a9b8-5cf632e30793 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "chatbot_dataset"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Load your dataset (adjust the path as necessary)\n",
        "chatbot_dataset = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AAI-520/Final Project/GenAI-Chatbot/dataset.csv\")\n",
        "\n",
        "chatbot_dataset.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN8jar6cVSaU",
        "outputId": "4f41dd00-8d68-47f9-f4d8-da0c392fc7ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 141674\n",
            "Validation set size: 35419\n",
            "Test set size: 44274\n"
          ]
        }
      ],
      "source": [
        "# Assuming chatbot_dataset is already defined\n",
        "# Sample 30% of the dataset before splitting\n",
        "# sampled_dataset = chatbot_dataset.sample(frac=0.3, random_state=42)\n",
        "\n",
        "# Split the dataset into train and test sets (80% train, 20% test)\n",
        "train_data, test_data = train_test_split(chatbot_dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further split the train data into training and validation sets (80% train, 20% validation)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the sizes of the sampled datasets\n",
        "print(f\"Training set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1waTXyvQowh",
        "outputId": "255ddfe6-daca-4a8c-a3c2-dd325a0fc67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the GPT-2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Set pad token to be the same as the end-of-sequence token\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FZQORICEVXEU"
      },
      "outputs": [],
      "source": [
        "# Define a new dataset class to maintain context with limited history and turn markers\n",
        "class ContextualChatbotDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=100, history_window=3):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.history_window = history_window  # Number of turns to retain in history\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the conversation history and the response\n",
        "        # Split conversation history by the [SEP] token between turns\n",
        "        conversation_history = self.data['conversation_history'].iloc[idx].split(\" [SEP] \")\n",
        "        response = self.data['response'].iloc[idx]\n",
        "\n",
        "        # Limit the conversation history to the last `history_window` turns\n",
        "        limited_history = conversation_history[-self.history_window:]\n",
        "\n",
        "        # Add special tokens for user and bot turns\n",
        "        input_text = f\"[USER] {' [BOT] '.join(limited_history)} [BOT] {response}\"\n",
        "\n",
        "        # Tokenize the input\n",
        "        encodings = self.tokenizer.encode_plus(\n",
        "            input_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt',\n",
        "            return_attention_mask=True,\n",
        "            add_special_tokens=True,\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encodings['input_ids'].squeeze(0),  # Remove batch dimension\n",
        "            'attention_mask': encodings['attention_mask'].squeeze(0),  # Remove batch dimension\n",
        "            'labels': encodings['input_ids'].squeeze(0),  # Set labels to input_ids for language modeling\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "# Create datasets for training, validation, and testing\n",
        "train_dataset = ContextualChatbotDataset(train_data, tokenizer, history_window=3)  # Limit to last 3 turns\n",
        "val_dataset = ContextualChatbotDataset(val_data, tokenizer, history_window=3)\n",
        "test_dataset = ContextualChatbotDataset(test_data, tokenizer, history_window=3)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, num_workers=4, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, num_workers=4, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ0iMLG-Bv4V",
        "outputId": "d383798c-3a00-4696-c860-63ce6417bd77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Training Loss: 1.3865, Validation Loss: 1.5712, Time: 2073.36 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Training Loss: 1.0981, Validation Loss: 1.4343, Time: 2072.74 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Training Loss: 1.1318, Validation Loss: 1.3254, Time: 2073.01 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Training Loss: 1.2070, Validation Loss: 1.2359, Time: 2072.82 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5: 100%|██████████| 4428/4428 [32:00<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Training Loss: 1.1168, Validation Loss: 1.1642, Time: 2073.65 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 6: 100%|██████████| 4428/4428 [32:00<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, Training Loss: 1.1244, Validation Loss: 1.1058, Time: 2073.88 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 7: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7, Training Loss: 1.1212, Validation Loss: 1.0580, Time: 2073.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 8: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8, Training Loss: 1.2421, Validation Loss: 1.0230, Time: 2072.70 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 9: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, Training Loss: 0.7882, Validation Loss: 0.9819, Time: 2072.85 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 10: 100%|██████████| 4428/4428 [32:00<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Training Loss: 0.9374, Validation Loss: 0.9487, Time: 2073.46 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 11: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11, Training Loss: 0.6037, Validation Loss: 0.9209, Time: 2072.87 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 12: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12, Training Loss: 0.7389, Validation Loss: 0.8970, Time: 2072.92 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 13: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13, Training Loss: 0.8516, Validation Loss: 0.8739, Time: 2073.04 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 14: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14, Training Loss: 0.7135, Validation Loss: 0.8674, Time: 2072.97 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 15: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15, Training Loss: 0.5070, Validation Loss: 0.8453, Time: 2073.05 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 16: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16, Training Loss: 0.8631, Validation Loss: 0.8331, Time: 2073.05 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 17: 100%|██████████| 4428/4428 [32:00<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17, Training Loss: 0.8977, Validation Loss: 0.8118, Time: 2073.52 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 18: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18, Training Loss: 0.6401, Validation Loss: 0.8024, Time: 2073.15 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 19: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19, Training Loss: 0.4508, Validation Loss: 0.7969, Time: 2073.02 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 20: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20, Training Loss: 0.4625, Validation Loss: 0.7902, Time: 2072.84 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 21: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21, Training Loss: 0.8175, Validation Loss: 0.7798, Time: 2072.78 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 22: 100%|██████████| 4428/4428 [31:58<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22, Training Loss: 0.6263, Validation Loss: 0.7762, Time: 2072.06 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 23: 100%|██████████| 4428/4428 [31:58<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23, Training Loss: 0.3299, Validation Loss: 0.7744, Time: 2072.36 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 24: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24, Training Loss: 0.4153, Validation Loss: 0.7633, Time: 2072.96 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 25: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25, Training Loss: 0.5757, Validation Loss: 0.7608, Time: 2072.73 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 26: 100%|██████████| 4428/4428 [31:59<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26, Training Loss: 0.3669, Validation Loss: 0.7584, Time: 2072.59 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 27: 100%|██████████| 4428/4428 [31:58<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27, Training Loss: 0.2541, Validation Loss: 0.7590, Time: 2072.18 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 28: 100%|██████████| 4428/4428 [31:58<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28, Training Loss: 0.3629, Validation Loss: 0.7508, Time: 2071.97 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 29: 100%|██████████| 4428/4428 [31:58<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29, Training Loss: 0.4363, Validation Loss: 0.7475, Time: 2071.97 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 30: 100%|██████████| 4428/4428 [31:58<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30, Training Loss: 0.7671, Validation Loss: 0.7487, Time: 2071.79 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 31: 100%|██████████| 4428/4428 [31:58<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31, Training Loss: 0.3689, Validation Loss: 0.7556, Time: 2071.91 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 32: 100%|██████████| 4428/4428 [31:58<00:00,  2.31it/s]\n",
            "Validating: 100%|██████████| 1107/1107 [02:33<00:00,  7.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32, Training Loss: 0.3124, Validation Loss: 0.7554, Time: 2071.93 seconds\n",
            "Early stopping triggered after 32 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the pre-trained GPT-2 model\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Check for GPU Availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Move the model to the GPU\n",
        "model.to(device)\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training Loop with Validation and Early Stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 3  # Number of epochs to wait for improvement\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(50):  # Number of epochs\n",
        "    start_time = time.time()  # Start time for the epoch\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    # Training phase\n",
        "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\"):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move input data to the GPU\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        # Compute the loss\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            # Move input data to the GPU\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            # Compute the loss\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "    # Calculate the time taken for the epoch\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "\n",
        "    # Print training and validation losses along with epoch time\n",
        "    print(f\"Epoch: {epoch + 1}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss / len(val_loader):.4f}, Time: {epoch_time:.2f} seconds\")\n",
        "\n",
        "    # Check for improvement\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_without_improvement = 0  # Reset the counter\n",
        "        # Optionally, save the model checkpoint here\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBNVDt0SZYix",
        "outputId": "f03120ef-a82a-40df-c568-f3a3006b9b90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Colab Notebooks/AAI-520/Final Project/GenAI-Chatbot/eval/gpt/base_gpt_tokenizer_3_actual/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AAI-520/Final Project/GenAI-Chatbot/eval/gpt/base_gpt_tokenizer_3_actual/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AAI-520/Final Project/GenAI-Chatbot/eval/gpt/base_gpt_tokenizer_3_actual/vocab.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AAI-520/Final Project/GenAI-Chatbot/eval/gpt/base_gpt_tokenizer_3_actual/merges.txt',\n",
              " '/content/drive/MyDrive/Colab Notebooks/AAI-520/Final Project/GenAI-Chatbot/eval/gpt/base_gpt_tokenizer_3_actual/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Saving the model\n",
        "gpt_model = \"/content/drive/MyDrive/Colab Notebooks/AAI-520/Final Project/GenAI-Chatbot/eval/gpt/base_gpt_model_3_actual\"\n",
        "gpt_tokenizer = \"/content/drive/MyDrive/Colab Notebooks/AAI-520/Final Project/GenAI-Chatbot/eval/gpt/base_gpt_tokenizer_3_actual\"\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained(gpt_model)\n",
        "tokenizer.save_pretrained(gpt_tokenizer)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}